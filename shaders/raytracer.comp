#version 460 core

layout (local_size_x = 32, local_size_y = 32, local_size_z = 1) in;

layout (rgba32f, binding = 0) uniform image2D imgOutput;

layout (location = 0) uniform float time;

layout (location = 1) uniform mat4 camera_view;
layout (location = 2) uniform bool orthographic;
layout (location = 5) uniform float near_plane;
layout (location = 6) uniform float far_plane;

layout (std430, binding = 10) buffer Pos { vec4 positions[]; };
layout (std430, binding = 11) buffer Col { vec4 colors[]; };
layout (std430, binding = 12) buffer Rad { float radius[]; };

uint rng_state;
const float PI = 3.14159265f;

#define N_BOUNCES 10
#define N_SAMPLES 10

struct hit_t {
  bool hit;
  vec3 normal;
  vec3 position;
  vec3 color;
};

uint rand_xorshift() {
  rng_state ^= (rng_state << 13);
  rng_state ^= (rng_state >> 17);
  rng_state ^= (rng_state << 5);
  return rng_state;
}

float rand() {
  return float(rand_xorshift()) * (1.0 / 4294967296.0);
}

// https://www.shadertoy.com/view/WttXWX
uint hash_lowbias32(uint x) {
  x ^= x >> 16;
  x *= 0x7feb352dU;
  x ^= x >> 15;
  x *= 0x846ca68bU;
  x ^= x >> 16;
  return x;
}

mat3 get_tangent_space(vec3 normal) {
  vec3 helper = vec3(1, 0, 0);
  if (abs(normal.x) > 0.99f)
    helper = vec3(0, 0, 1);

  vec3 tangent = normalize(cross(normal, helper));
  vec3 binormal = normalize(cross(normal, tangent));
  return mat3(tangent, binormal, normal);
}

// http://three-eyed-games.com/2018/05/12/gpu-path-tracing-in-unity-part-2/
vec3 sample_hemisphere(vec3 normal) {
  // Uniformly sample hemisphere direction
  float cosTheta = rand();
  float sinTheta = sqrt(max(0.0f, 1.0f - cosTheta * cosTheta));
  float phi = 2 * PI * rand();
  vec3 tangent_space_dir = vec3(cos(phi) * sinTheta, sin(phi) * sinTheta, cosTheta);
  // Transform direction to world space
  return tangent_space_dir * get_tangent_space(normal);
}


hit_t cast_ray(vec3 ray_origin, vec3 ray_direction) {
  uint n_spheres = 10;
  vec3 pixel_color = vec3(0.0, 0.0, 0.0);

  float hit_distance = far_plane;
  int sphere_hit_id = -1;
  vec3 normal = vec3(0.0, 0.0, 0.0);
  vec3 hit_position = vec3(0.0, 0.0, 0.0);

  for (int i = 0; i < n_spheres; i++) {
    vec4 position = camera_view * positions[i];
    if (!orthographic) {
      position *= -1;
    }

    // Equation for ray hitting a sphere:
    // (ray_origin + ray_direction * t - position)^2 = radius^2
    // O = ray_origin
    // D = ray_direction
    // C = sphere center
    // omc = O - C
    // bsqmc = B^2 - C
    // iff bsqmc >= 0 then there is a hit
    vec3 omc = ray_origin - position.xyz;
    float b = dot(ray_direction, omc);
    float c = dot(omc, omc) - radius[i]* radius[i];
    float bsqmc = b * b - c;

    if (bsqmc >= 0.0) {
      float t = -b - sqrt(bsqmc);
      if (t > near_plane && t < hit_distance) {
        hit_distance = t;
        sphere_hit_id = i;

        // Calculate the normal of the sphere at the hit point
        normal = normalize(ray_origin + ray_direction * t - position.xyz);
        hit_position = ray_origin + ray_direction * t;
      }
    }
  }

  if (sphere_hit_id >= 0) {
    pixel_color.rgb = colors[sphere_hit_id].rgb * dot(normal, (ray_origin - ray_direction));
  }

  hit_t hit = hit_t(
    sphere_hit_id >= 0,
    normal,
    hit_position.xyz,
    pixel_color
  );

  return hit;
}


void main() {
  rng_state = hash_lowbias32(gl_GlobalInvocationID.x * gl_GlobalInvocationID.y + gl_GlobalInvocationID.x + int(mod(time * 100000.0, 100000000)));

  vec4 pixel_color = vec4(0.0, 0.0, 0.0, 1.0);
  ivec2 pixel_position = ivec2(gl_GlobalInvocationID.xy);
  ivec2 texture_size = imageSize(imgOutput);
  vec4 old_color = imageLoad(imgOutput, pixel_position);

  float aspect_ratio = float(texture_size.x) / float(texture_size.y);
  float max_y = 5.0;
  float max_x = max_y * aspect_ratio;

  for (int i_sample = 0; i_sample < N_SAMPLES; i_sample++) {
    // Build a x,y in clip space (ie -1 to 1)
    float x = (float(pixel_position.x * 2 - texture_size.x) / texture_size.x);
    float y = (float(pixel_position.y * 2 - texture_size.y) / texture_size.y);

    // Build a ray from the camera position pointing forward (negative z)
    // Orthographic projection:
    vec3 ray_origin = vec3(x * max_x, y * max_y, 0.0);
    vec3 ray_direction = vec3(0.0, 0.0, -1.0);

    // Perspective projection:
    if (!orthographic) {
      ray_origin = vec3(0.0, 0.0, 0.0);
      ray_direction = normalize(ray_origin - vec3(x * max_x, y * max_y, -10.0));
    }

    //vec4 result = vec4(0.0, 0.0, 0.0, 0.0);
    vec4 result = vec4(1.0, 1.0, 1.0, 1.0);

    for (int i = 0; i < N_BOUNCES; i++) {
      hit_t hit_info = cast_ray(ray_origin, ray_direction);

      if (!hit_info.hit)
        break;

      // FIXME; This is not how light works. Need to account for energy loss
      result.rgb *= hit_info.color;
      //ray_origin = hit_info.position + hit_info.normal * 0.001;
      ray_origin = hit_info.position;

      if (rand() < 0.5)
        ray_direction = reflect(ray_direction, hit_info.normal);
      else
        ray_direction = normalize(sample_hemisphere(hit_info.normal));
    }

    pixel_color.rgb += result.rgb / float(N_SAMPLES);
  }

  vec4 final_color = vec4((old_color + pixel_color).rgb, old_color.a + 1);
  if (time < 0.1) {
    final_color = pixel_color;
  }
  imageStore(imgOutput, pixel_position, final_color);
}
